{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "albums = pd.DataFrame({'spotify_id': pd.Series(dtype='str'),\n",
    "    'youtube_id': pd.Series(dtype='str'),\n",
    "    'project_name': pd.Series(dtype='str'),\n",
    "    'artist': pd.Series(dtype='str'),\n",
    "    'project_type': pd.Series(dtype='str'),\n",
    "    'tracks': pd.Series(dtype='int'),\n",
    "    'project_art': pd.Series(dtype='str'),\n",
    "    'year': pd.Series(dtype='int'),\n",
    "    'rating': pd.Series(dtype='int')})\n",
    "\n",
    "\n",
    "tracks = pd.DataFrame({'spotify_id': pd.Series(dtype='str'),\n",
    "        'album_id': pd.Series(dtype='str'),\n",
    "        'youtube_id': pd.Series(dtype='str'),\n",
    "        'name': pd.Series(dtype='str'),\n",
    "        'duration': pd.Series(dtype='int'),\n",
    "        'explicit': pd.Series(dtype='bool'),\n",
    "        'preview': pd.Series(dtype='str'),\n",
    "        'key': pd.Series(dtype='int'),\n",
    "        'mode': pd.Series(dtype='int'),\n",
    "        'acousticness': pd.Series(dtype='float'),\n",
    "        'danceability': pd.Series(dtype='float'),\n",
    "        'energy': pd.Series(dtype='float'),\n",
    "        'instrumentalness': pd.Series(dtype='float'),\n",
    "        'liveness': pd.Series(dtype='float'),\n",
    "        'loudness': pd.Series(dtype='float'),\n",
    "        'speechiness': pd.Series(dtype='float'),\n",
    "        'valence': pd.Series(dtype='float'),\n",
    "        'tempo': pd.Series(dtype='float')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  spotify_id   youtube_id                project_name  \\\n",
      "0     2sP7yg2lk1x7k8bKyuD9dZ  KdoJNfTm-Hc                   crossfire   \n",
      "1     0qY6lBQSi8IMJjHYDPdAqX  Qqw9bnffDsY                 james blake   \n",
      "2     4vLYreWxd2ptOAzPwTyBI3  GlToEXQO2yc                       sr3mm   \n",
      "3     5FXlBbOLPltg9Ix0Ri7G01  nhndrX8cktI                 self-titled   \n",
      "4     768qk0nBofLKV24omUQd8w  57r3E3XRNRk             twisted crystal   \n",
      "...                      ...          ...                         ...   \n",
      "6888  392p3shh2jkxUxY2VHvlH8  RG8FKXlGdBU              channel orange   \n",
      "6889  4KXekRRcMRpdGX3jlPBqTP  f0D9IyyeEEU               floral shoppe   \n",
      "6890  162AQYS4VkC7Hx3l2EBASj  K7nxzVgxlhY                 drunk girls   \n",
      "6891  3bq3v9Fp24GXbSQcOYpAuj  XmSktY7RhAE          acousmatic sorcery   \n",
      "6892  6MWXESNF37POkyhlvBslvU  NImDLA14kHs  take the kids off broadway   \n",
      "\n",
      "                artist project_type  tracks  \\\n",
      "0      brandon flowers        track       2   \n",
      "1          james blake        album      11   \n",
      "2         rae sremmurd        album      27   \n",
      "3          alice glass           ep       6   \n",
      "4        guerilla toss        album       9   \n",
      "...                ...          ...     ...   \n",
      "6888       frank ocean        album      17   \n",
      "6889    macintosh plus        album       1   \n",
      "6890   lcd soundsystem        album       1   \n",
      "6891  willis earl beal        album      12   \n",
      "6892           foxygen           ep       7   \n",
      "\n",
      "                                            project_art  year  rating  \n",
      "0     https://i.scdn.co/image/ab67616d000048517a300b...  2015       7  \n",
      "1     https://i.scdn.co/image/ab67616d00004851a6b49c...  2011       7  \n",
      "2     https://i.scdn.co/image/ab67616d00004851ba9015...  2018       7  \n",
      "3     https://i.scdn.co/image/ab67616d0000485197822a...  2017       7  \n",
      "4     https://i.scdn.co/image/ab67616d00004851baabef...  2018       8  \n",
      "...                                                 ...   ...     ...  \n",
      "6888  https://i.scdn.co/image/ab67616d000048517aede4...  2012       7  \n",
      "6889  https://i.scdn.co/image/ab67616d0000485144733c...  2020       4  \n",
      "6890  https://i.scdn.co/image/ab67616d0000485133f729...  2011       7  \n",
      "6891  https://i.scdn.co/image/ab67616d00004851de1434...  2012       4  \n",
      "6892  https://i.scdn.co/image/ab67616d00004851821002...  2012       8  \n",
      "\n",
      "[6893 rows x 9 columns]\n",
      "                   spotify_id                album_id   youtube_id  \\\n",
      "0      6e7hIhOLH9zvb3zP5O5gt0  1jToVugwBEzcak8gJNZG2f  B7oeiUvMqXA   \n",
      "1      4gRHuRT9eQOXiUf5hnEWr9  4GHc9W3Uscx49TDa2ssFd1  J6CCJNs-Iso   \n",
      "2      31b2VLhxvtE8NQoVkSnm8a  39CD7YD6Zg6eFxNVwEnUU3  d3MJLRnWAxQ   \n",
      "3      2AobDJxjDp5TbxGdR3JGen  0O82niJ0NpcptYRxogeEZu  ylHizJmmJM4   \n",
      "4      7GDj2BjZSTdl6r9bnffkFD  6CL2rdgPpUEXwWsNjexAZ5  1Qy-Gs9hMq0   \n",
      "...                       ...                     ...          ...   \n",
      "75134  21RWPwsKElNTKx7Vf03Dfr  7AS9VaIdnYSR13T3vkVtu9  bO4nntxCsz4   \n",
      "75135  5hA2yBJsczFO6SQlFQJSo7  5XqENSDSTSveo4eBTwjrW1  1RuC_S06xwY   \n",
      "75136  3zXGKNcbFG98UtAC5CyyYW  5mdfU5YxMPnwFwJQMC9rBj  bRPT-bxzQxw   \n",
      "75137  3sZnMMojrkwOxzdV1zUf2J  4hnlvhL0RR3AH2YOVChSsh  JKM79q5lKVM   \n",
      "75138  5uoJXCajb85s8v8lOqe1uV  799qo6A5q4TXn9j3tVcc82  Blz9I0q2Hq8   \n",
      "\n",
      "                              name  duration  explicit  \\\n",
      "0                          BOY BYE    142186      True   \n",
      "1                      Total Relax    352999     False   \n",
      "2                             Myth     78693      True   \n",
      "3            Let the Groove Get In    431613     False   \n",
      "4               Gold (Bonus Track)    211825     False   \n",
      "...                            ...       ...       ...   \n",
      "75134              Beginnerâ€™s Mind    135453     False   \n",
      "75135                  Kitchenette    316680     False   \n",
      "75136           Manic in the Grips     58400     False   \n",
      "75137                Within Thrall    337980     False   \n",
      "75138  The Teeth Behind The Kisses    192813     False   \n",
      "\n",
      "                                                 preview  key  mode  \\\n",
      "0      https://p.scdn.co/mp3-preview/ef0139248dd83735...    9     1   \n",
      "1      https://p.scdn.co/mp3-preview/cf7d4ae7f73a7880...    3     0   \n",
      "2      https://p.scdn.co/mp3-preview/15a913e510b179c9...    4     1   \n",
      "3      https://p.scdn.co/mp3-preview/acee40a320b1eccb...    4     0   \n",
      "4      https://p.scdn.co/mp3-preview/a6d4c2617949535c...   10     1   \n",
      "...                                                  ...  ...   ...   \n",
      "75134  https://p.scdn.co/mp3-preview/56d0424a165dd0a8...    0     1   \n",
      "75135  https://p.scdn.co/mp3-preview/2bb9b68fb2349295...    5     1   \n",
      "75136  https://p.scdn.co/mp3-preview/7d9f89607135458d...    1     1   \n",
      "75137  https://p.scdn.co/mp3-preview/6f73e141d7d63fa4...   10     0   \n",
      "75138  https://p.scdn.co/mp3-preview/0497fbd29ce4a7e2...   10     0   \n",
      "\n",
      "       acousticness  danceability  energy  instrumentalness  liveness  \\\n",
      "0          0.512000         0.869  0.7470          0.000000    0.1240   \n",
      "1          0.754000         0.313  0.2870          0.935000    0.1010   \n",
      "2          0.003980         0.508  0.4090          0.000000    0.1960   \n",
      "3          0.204000         0.785  0.8410          0.002350    0.2900   \n",
      "4          0.794000         0.441  0.3010          0.026500    0.1070   \n",
      "...             ...           ...     ...               ...       ...   \n",
      "75134      0.957000         0.558  0.1830          0.000845    0.1090   \n",
      "75135      0.009610         0.411  0.6210          0.000000    0.1220   \n",
      "75136      0.000003         0.442  0.9890          0.152000    0.7650   \n",
      "75137      0.000007         0.181  0.9420          0.714000    0.1120   \n",
      "75138      0.030500         0.173  0.0158          0.846000    0.0858   \n",
      "\n",
      "       loudness  speechiness  valence    tempo  \n",
      "0        -7.143       0.1510   0.7840  124.932  \n",
      "1       -21.192       0.0489   0.1150   65.125  \n",
      "2        -7.909       0.1890   0.5730   73.679  \n",
      "3        -5.962       0.0640   0.4370  116.921  \n",
      "4        -9.725       0.0283   0.0779  147.151  \n",
      "...         ...          ...      ...      ...  \n",
      "75134   -17.337       0.0343   0.3060  106.038  \n",
      "75135    -5.487       0.0299   0.3220   71.007  \n",
      "75136    -2.872       0.0857   0.4830   91.841  \n",
      "75137    -7.231       0.0982   0.1330  152.130  \n",
      "75138   -33.536       0.0396   0.0494  109.196  \n",
      "\n",
      "[75139 rows x 18 columns]\n"
     ]
    }
   ],
   "source": [
    "import glob \n",
    "\n",
    "#recombine the csvs into a dataframe \n",
    "RECOMBINE_FILES = True\n",
    "\n",
    "path = './data' # use your path\n",
    "track_files = glob.glob(path + \"/tracks20*.csv\")\n",
    "album_files = glob.glob(path + \"/albums20*.csv\")\n",
    "\n",
    "album_li = []\n",
    "track_li = []\n",
    "\n",
    "if RECOMBINE_FILES:\n",
    "    for filename in album_files:\n",
    "        df = pd.read_csv(filename, index_col=0, header=0, dtype=dict(albums.dtypes))\n",
    "        album_li.append(df)\n",
    "\n",
    "    album_df = pd.concat(album_li, axis=0, ignore_index=True)\n",
    "\n",
    "\n",
    "    for filename in track_files:\n",
    "        df = pd.read_csv(filename, index_col=0, header=0,dtype=dict(tracks.dtypes))\n",
    "        track_li.append(df)\n",
    "\n",
    "    track_df = pd.concat(track_li, axis=0, ignore_index=True)\n",
    "\n",
    "    album_df.to_csv('./data/albums.csv')\n",
    "\n",
    "    track_df.to_csv('./data/tracks.csv')\n",
    "else:\n",
    "    album_df = pd.read_csv('./data/albums.csv')\n",
    "    track_df = pd.read_csv('./data/tracks.csv')\n",
    "\n",
    "album_df = album_df.sample(frac=1).reset_index(drop=True)\n",
    "track_df = track_df.sample(frac=1).reset_index(drop=True)\n",
    "print(album_df)\n",
    "print(track_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Input, Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Concatenate\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, MinMaxScaler\n",
    "from math import floor\n",
    "from random import sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "#set up encoders\n",
    "artists = album_df[\"artist\"].to_numpy().reshape(-1,1)\n",
    "artist_encoder = OrdinalEncoder().fit(artists)\n",
    "\n",
    "project_types = album_df[\"project_type\"].to_numpy().reshape(-1,1)\n",
    "project_type_encoder = OneHotEncoder().fit(project_types)\n",
    "\n",
    "def create_tracks_input(row):\n",
    "    out = []\n",
    "\n",
    "    #get all tracks for a single album\n",
    "    tracks = track_df[track_df['album_id'] == row['spotify_id']]\n",
    "    tracks_count = len(tracks)\n",
    "    for i, track_data in enumerate(tracks.iterrows()):\n",
    "        print(f\"Processing track: {i}/{tracks_count} (id {track_data[0]})\")\n",
    "        track = track_data[1]\n",
    "        out.append(\n",
    "            [\n",
    "                track[\"key\"],\n",
    "                track[\"mode\"],\n",
    "                track[\"acousticness\"],\n",
    "                track['danceability'],\n",
    "                track['energy'],\n",
    "                track['instrumentalness'],\n",
    "                track['liveness'],\n",
    "                track['loudness'],\n",
    "                track['speechiness'],\n",
    "                track['valence'],\n",
    "                track['tempo']\n",
    "            ]\n",
    "        )\n",
    "    print(out)\n",
    "    return out\n",
    "\n",
    "\n",
    "def create_input_row(row):\n",
    "    out = []\n",
    "    #out.append(row.name) # need to have a row id included to relate to tracks\n",
    "    out.append(artist_encoder.transform([[row['artist']]])[0][0])\n",
    "    project_type_encoded = project_type_encoder.transform([[row['project_type']]]).toarray()\n",
    "    out.extend(project_type_encoded[0])\n",
    "    out.append(row['year'])\n",
    "    out.append(int(row['tracks']))\n",
    "    return out\n",
    "\n",
    "ratings = to_categorical(album_df[\"rating\"])\n",
    "\n",
    "album_in = album_df.apply(create_input_row,axis=1,result_type='expand')\n",
    "album_in = MinMaxScaler().fit_transform(album_in)\n",
    "\n",
    "track_in = album_df.apply(create_tracks_input,axis=1,result_type='expand')\n",
    "track_in = MinMaxScaler().fit_transform(track_in)\n",
    "\n",
    "test_ratings = ratings[:test_amt]\n",
    "test_in = album_in[:test_amt]\n",
    "\n",
    "print(len(album_in))\n",
    "print(len(track_in))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_split = 0.2\n",
    "validation_split = 0.4\n",
    "test_amt = floor(test_split * len(album_df))\n",
    "\n",
    "print(album_in)\n",
    "print(track_in)\n",
    "\n",
    "track_input = Input(shape=(len(track_in[0])*album_df[\"tracks\"],))\n",
    "\n",
    "\n",
    "album_input = Input(shape=(len(album_in[0]),))\n",
    "model = Dense(256,activation='relu')(album_input)\n",
    "model = Dense(256,activation='relu')(model)\n",
    "output = Dense(len(ratings[0]),activation='softmax')(model)\n",
    "\n",
    "\n",
    "model = Model(inputs=album_input,outputs=output)\n",
    "model.summary()\n",
    "opt = Adam(learning_rate=0.000001)\n",
    "model.compile(optimizer=opt,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model.fit(album_in,ratings,batch_size=32, epochs=25, validation_split=validation_split,shuffle=True,verbose=1)\n",
    "\n",
    "\n",
    "\n",
    "#evaluate\n",
    "\n",
    "model.evaluate(test_in,test_ratings)\n",
    "\n",
    "\n",
    "#output: eleven units for rating 0-10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9650cb4e16cdd4a8e8e2d128bf38d875813998db22a3c986335f89e0cb4d7bb2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
